Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
 [1644/1644 40:01, Epoch 3/3]
Step	Training Loss
500	1.950700
1000	1.094900
1500	0.739500
Training Time: 2403.69s
Evaluation Accuracy: 0.57
Average Inference Time per Batch: 0.0106 seconds
Running scenario: Only Compression
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: resume_download is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use force_download=True.
  warnings.warn(
Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
 [1644/1644 40:35, Epoch 3/3]
Step	Training Loss
500	2.017000
1000	1.137400
1500	0.832000
Training Time: 2437.31s
Evaluation Accuracy: 0.56
Average Inference Time per Batch: 0.0144 seconds
Running scenario: Only Distributed
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: resume_download is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use force_download=True.
  warnings.warn(
Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
 [1131/1644 27:48 < 12:38, 0.68 it/s, Epoch 2.06/3]
Step	Training Loss
500	1.911500
1000	1.086200
 [1644/1644 40:25, Epoch 3/3]
Step	Training Loss
500	1.911500
1000	1.086200
1500	0.751000
Training Time: 2427.34s
Evaluation Accuracy: 0.56
Average Inference Time per Batch: 0.0108 seconds
Running scenario: Distributed + Compression
/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: resume_download is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use force_download=True.
  warnings.warn(
Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
 [1501/1644 36:57 < 03:31, 0.68 it/s, Epoch 2.74/3]
Step	Training Loss
500	2.017000
1000	1.137400